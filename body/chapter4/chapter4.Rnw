% !TeX root = ./main.Rnw
%\SweaveUTF8

\chapter{Análisis de Resultados}

\section{Análisis Exploratorio de los datos}

En el presente capítulo se realiza la descripción de los resultados obtenidos luego de la aplicación del método propuesto para la simulación de la estrategia. De igual modo, se presentan los coeficientes arrojados por el MLG así como un analisis de los componentes principales para el índice S\&P500 


\subsection{Análisis de los Índices}

En la figura 4.1 se observa el precio de cierre de cada índice durante el período de estudio. Se puede apreciar que en general los cinco mercados tienen tendencia a la alta. En general para el S\&P y NASDAQ se aprecia una menor variabilidad que en los demás índices.

<<Index_Graph, echo=FALSE>>=
plot_serie <- list()
for(i in 1:5){
  .aux_plot <- list_serie[[i]] %>%
    ggplot(aes(x = timestamp, y = close)) +
    geom_line() +
    labs(x = 'Fecha', y = 'Precio de Cierre', title = serie[i]) +
    theme_minimal(base_size = 8) +
    scale_y_continuous(labels = scales::number)

  plot_serie %<>% rlist::list.append(.aux_plot)
}
@

\begin{figure}[H]
\setkeys{Gin}{width = 0.8 \textwidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
do.call('grid.arrange', plot_serie)
@
\caption{Precios de Cierre de los índices en el período de estudio (26/10/2008 - 18/01/2019)}
\end{figure}

Las curvas del S\&P y NASDAQ son muy parecidas ya que ambas representan cotizaciones de las mayores empresas americanas. Se aprecia un crecimiento sostenido desde el año 2009, con algunos períodos mas estables, a principios del 2016 -por la polémica victoria de Donald Trump como presidente- y en 2018 provocado por el miedo a un incremento en las tasas de interés por parte de la Reserva Federal y las tensas negociaciones con China.

Por su parte el NIKKEI es el índice bursátil de la bolsa de Tokio, resume las cotizaciones de 225 grandes empresas de Japón de distintos sectores industriales. Al ver la gráfica de sus cotizaciones se observa un rápido crecimiento entre 2009 y 2010, sin embargo con la ocurrencia del terremoto registrado en el norte del país a principios del 2011 el índice se vio afectado y llegó a su nivel más bajo de 8160 puntos el 25 de noviembre desde el 10 de marzo de 2009. La recuperación ocurrió en 2013 debido a los cambios implementados por el país en materia de política fiscal y monetaria. El Gobierno impulsó el gasto público y el Banco Central de Japón inyectó dinero en la economía a gran escala.

El FTSE 100 es un índice bursátil calculado con las cotizaciones de las 100 empresas más grandes de Reino Unido, en su gráfica se observa una tendencia alcista aunque con mayor ruido o variabilidad que los otros índices Se puede apreciar una caída en las cotizaciones el año 2015 debido a resultados negativos mostrados por la actividad manufacturera en Asia, especialmente en China. Esto afecta los mercados europeos dada que este es el principal consumidor del mercado asiático.

Por último el índice BOVESPA representa las 50 empresas de mayor capitalización de la Bolsa de Valores de Sao Paulo. Se aprecia que a diferencia de los anteriores, éste mantiene una tendencia a la baja hasta 2016 debido a la recesión económica sufrida por Brasil mostrando una contracción del PIB en un 3.8\% para 2015. Aunado a factores ambientales como el virus del Zika y el escándalo de corrupción de Petrobras. A partir de 2016 con la inflación gradualmente bajo control y tasas de interés en decrecimiento, la confianza de los inversores llevó a un rápido crecimiento del índice en los últimos tres años.

\subsection{Análisis de las Variables Predictoras}

\begin{figure}[H]
\setkeys{Gin}{width = 0.6\textwidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
list_serie[[1]] %>% createIndicators(full = TRUE) %>% 
    filter(year(timestamp) %in% seq(2009, 2012, 1)) %>% 
    select(-one_of('timestamp')) %>%  
    na.omit() %>%
    cor() %>% 
    corrplot::corrplot(method = 'number', type = 'lower', order = 'hclust', tl.col = 'black',
                   col.pos = 'r', cl.pos = 'r', number.cex = 0.65, number.digits = 1)

@
\caption{Correlación entre indicadores originales calculados con los precios del S\&P500 en el primer período de entrenamiento(01/01/2009 - 31/12/2012)}
\end{figure}

En la figura 4.2 se observa la correlación de las variables originales para el primer período de entrenamiento del índice S\&P500. Como se puede observar existe alta correlación entre las distintas variables del precio (Apertura, Cierre, Máximo y Mínimo) por lo que se decidió trabajar solo con los precios de cierre dado que ésta es la misma utilizada para determinar la variable dependiente. Así mismo se observa alta correlación entre los rezagos de los rendimientos, para esto se decidió trabajar solo con los rezagos de 1, 3 y 5 períodos. Por su parte se descarta la variable dip -elemento utilizado en el indicador ADX- por su fuerte correlación con el RSI. Se determina lo mismo para la banda inferior del indicador de Bollinger. En la figura 4.3 se muestra las correlaciones de las variables definitivas

\begin{figure}[H]
\setkeys{Gin}{width = 0.6\textwidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
list_serie[[1]] %>% createIndicators(full = FALSE) %>% 
    filter(year(timestamp) %in% seq(2009, 2012, 1)) %>% 
    select(-one_of('timestamp', 'open', 'high', 'low')) %>%  
    na.omit() %>% 
    cor() %>% 
    corrplot::corrplot(method = 'number', type = 'lower', order = 'hclust',
                     cl.pos = 'r', tl.col = 'black')
@
\caption{Correlación entre indicadores definitivos calculados con los precios del S\&P500 en el primer período de entrenamiento(01/01/2009 - 31/12/2012)}
\end{figure}

A continuación se presentan una serie de gráficos para reflejar lo anteriormente expuesto en cuanto a la relación entre los indicadores.

<<Descriptive_Plots, echo=FALSE>>=
var_predict <- list_serie[[1]] %>% 
    predict_tp(tp = .tp, sl = .sl, h = .h) %>%
    mutate(class_2 = factor(class)) %>%
    select(-one_of('class')) %>% 
    createIndicators(full = FALSE) %>% 
    filter(year(timestamp) %in% seq(2009, 2012, 1)) %>% 
    select(-one_of('timestamp', 'open', 'high', 'low')) %>%  
    na.omit()

# Box-plot's
.plot_OHLC <- var_predict %>% 
  select(c('class_2', 'close')) %>% 
  reshape2::melt() %>%
  ggplot(aes(x = variable, y = value, fill = class_2)) +
  geom_boxplot()

.plot_lags <- var_predict %>% 
  select(c('class_2', 'lag_1', 'lag_3', 'lag_5')) %>% 
  reshape2::melt() %>%
  ggplot(aes(x = variable, y = value, fill = class_2)) +
  geom_boxplot()

.plot_adx_rsi <- var_predict %>% 
  select(c('class_2', 'adx', 'rsi')) %>% 
  reshape2::melt() %>%
  ggplot(aes(x = variable, y = value, fill = class_2)) +
  geom_boxplot()

.plot_macd <- var_predict %>% 
  select(c('class_2', 'macd', 'macd_signal')) %>% 
  reshape2::melt() %>%
  ggplot(aes(x = variable, y = value, fill = class_2)) +
  geom_boxplot()

.plot_atr <- var_predict %>% 
  select(c('class_2', 'atr')) %>% 
  reshape2::melt() %>%
  ggplot(aes(x = variable, y = value, fill = class_2)) +
  geom_boxplot()

.plot_boxplot <- list(.plot_OHLC, .plot_lags, .plot_adx_rsi, .plot_macd, .plot_atr)

# Histogram
.ind <- names(var_predict)[-2]
.plot_hist <- list()
for(i in .ind){
  .histo_plot <- var_predict %>% 
    select(i) %>% 
    reshape2::melt() %>% 
    ggplot(aes(x = value)) +
    geom_histogram(color="darkblue", fill="lightblue") +
    labs(x = i)
  
  .plot_hist %<>% rlist::list.append(.histo_plot)
}

# Density
.plot_dens <- list()
for(i in .ind){
  .dens_plot <- var_predict %>% 
    select(c('class_2', i)) %>% 
    reshape2::melt() %>%
    ggplot(aes(x = value, color = class_2)) +
    geom_density() +
    labs(x = i)
  
  .plot_dens %<>% rlist::list.append(.dens_plot)
}

# list of all plots
descr_plots <- list(.plot_boxplot, .plot_hist, .plot_dens)
@

\begin{figure}[H]
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
# Box-Plot
do.call('grid.arrange', descr_plots[[1]])
@
\caption{Gráfico de cajas de indicadores definitivos calculados con los precios del S\&P500 en el primer período de entrenamiento(01/01/2009 - 31/12/2012)}
\end{figure}

En la figura 4.4 se observan gráficos de cajas para cada una de las variables predictoras, diferenciando entre los registros identificados como 'buy' y 'stay'. En el caso de la variable close, se aprecia que la caja está ligeramente mas abajo para los registros marcados como 'buy', señalando que efectivamente las entradas ocurren a precios bajos. En el caso los rezagos -lags- se observa que mientras mayor sea el número de períodos para su cálculo, más dispersos serán los valores y mayor diferencia existirá entre las clases.

Para la variable ADX la caja de los registros 'buy' está ligeramente más arriba que los 'stay' lo que indicaría que se debería comprar en tendencia alcista. Igualmente ocurre con la variable RSI lo que indicaría que se compra cuando se está cerca de un cambio de tendencia ó por el contrario la consolidación de la misma. Para la variable RSI se observa como la caja de los registros identificados como 'buy' esta más abajo y es más estrecha, por lo cual se inferiría que se debe comprar en períodos de baja volatilidad.

\begin{figure}[H]
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
# Histograms
do.call('grid.arrange', c(descr_plots[[2]], ncol = 2, nrow = 5))
@
\caption{Histogramas de frecuencia de indicadores definitivos calculados con los precios del S\&P500 en el primer período de entrenamiento(01/01/2009 - 31/12/2012)}
\end{figure}

En la figura 4.5 se observa histogramas de frecuencias para cada indicador. Se observa como la distribución de los rezagos es similar entre ellos, mostrando datos simétricos con picos en los valores cercanos a 0. En cuanto a la variable ATR se observa que los datos son asimétricos hacia la derecha con algunos casos atípicos cercanos a 30, mostrando que el índice en general es de baja volatilidad. Para el caso de la banda de bollinger, sigue una distribución muy parecida a la del valor de cierre de precio, una distribución asimétrica hacia la izquierda con algunos picos en la cola, lo que referencia una tendencia alcista. Por otro lado el ADX muestra una distribución asimétrica hacia la derecha con valores entre 10 y 20 lo cual indicaría que esta tendencia alcista del índice es constante pero lenta. 

La distibucion de la variable RSI es asimétrica hacia la izquierda con la mayor frecuencia entre los valores cercanos a 60, lo cual reforzaría lo indicado por los otros indicadores en cuanto a la tendencia del índice 

\begin{figure}[H]
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
# Density
do.call('grid.arrange', c(descr_plots[[3]], ncol = 2, nrow = 5))
@
\caption{Gráfico de densidad de indicadores definitivos calculados con los precios del S\&P500 en el primer período de entrenamiento(01/01/2009 - 31/12/2012)}
\end{figure}

En la figura 4.6 se observan gráficos de densidad para cada variable diferenciando entre clases, buscando algún comportamiento diferenciador. Sin embargo se muestra como para todos los indicadores la densidad es muy similar entre clases.

\subsection{Resultados del ACP}

A continuación se analizan los resultados de los componentes arrojados por el modelo en el primer período de entrenamiento (2009-2012) utilizando el índice S\&P500, en esta sección se referirá a ésta como 'matriz de datos'. Ahora bien, si se quisiera analizar cada una de las componentes arrojadas en cada muestra de entrenamiento se necesitaría repetir este análisis 30 veces lo cual no es práctico para los fines de la investigación. En este sentido se elaboró una aplicación con el paquete Shiny de R, para visualizar de manera interactiva las gráficas que ayudan a entender los componentes. La aplicación puede ser visitada con el siguiente enlace \url{https://rodserr.shinyapps.io/trading-ML/}.

<<PCA, echo=FALSE>>=
predictors_var <- list_serie[[1]] %>% predict_tp(tp = .tp, sl = .sl, h = .h) %>%
  mutate(class_2 = factor(class)) %>% #levels = c('stay', 'buy')))
  select(-one_of('class')) %>% 
  createIndicators() %>% 
  filter(year(timestamp) %in% seq(2009, 2012, 1)) %>% 
  getPredictors()

pca <- predictors_var %>% prcomp(scale = FALSE)

@

Los eigenvalores miden la cantidad de variación retenida por cada componente. Los eigenvalores son mayores para los primeros componentes, dado que el primer componente busca maximizar la cantidad de variación de la matriz de datos, por lo que cada vez es menor la cantidad de variación retenida por cada componente.

\begin{figure}[H]
\setkeys{Gin}{width = 0.8\textwidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
list_pca_eigen <- list(
  fviz_eig(pca, addlabels = TRUE, choice = 'eigenvalue') +
           labs(title = '', x = 'Componentes', y = 'Autovalores'),
  fviz_eig(pca, addlabels = TRUE, choice = 'variance') +
           labs(title = '', x = 'Componentes', y = '% Variabilidad explicada')
)

do.call('grid.arrange', list_pca_eigen)
@
\caption{Eigenvalores y Porcentaje de contribución para los 10 componentes más importantes obtenidos por la matríz de datos}
\end{figure}

La proporción de variación explicada por cada eigenvalor viene dada de dividir cada eigenvalor por su sumatoria, en este caso 45 -el número de variables originales-. Un eigenvalor mayor que 1 indica que el componente tiene mayor variación que la contenida en una de las variables originales. En la figura 4.7 se puede observar que el 85\% de la variación está contenida en los primeros 7 componentes. Igualmente se aprecia que el eigenvalor de los 10 PCs es mayor que 1. 

El número de componentes a utilizar se establece en función a estos dos gráficos. Este comportamiento anteriormente descrito se replica en los demás períodos de entrenamiento y demás pares. Se decide utilizar los dos primeros componentes como variables explicatorias en el MLG ya que la diferencia entre el 2do y 3er componentes es significativa, por lo que se espera que la variabilidad explicada en los dos primeros componentes -aproximadamente 50\%- sea suficiente. Esto también se basa en el hecho de que los indicadores son transformaciones del precio del activo por lo que existe correlación entre ellos. Se asume entonces que no es necesaria toda la información provista por los indicadores.


La contribución de las variables representan la variabilidad contenida en un componente. Las variables correlacionadas con el componente principal 1 (PC1) y PC2 son las más importantes en explicar la variabilidad en la matriz de datos. Aquellas que no se correlacionan con ninguna componente son desechadas por su baja contribución. En la figura 4.8 se observa la contribución de las primeras 30 variables en PC1, PC2 y la contribución obtenida en ambas.

\begin{figure}[H]
\setkeys{Gin}{width = 0.8\textwidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
list_contrib_pca <- list(
  # Contributions of variables to PC1
  fviz_contrib(pca, choice = "var", axes = 1, top = 30) +
    labs(y = '% Contribución', title = 'Contribución de variables a Com-1'),
  # Contributions of variables to PC2
  fviz_contrib(pca, choice = "var", axes = 2, top = 30) +
    labs(y = '% Contribución', title = 'Contribución de variables a Com-2'),

  fviz_contrib(pca, choice = "var", axes = 1:2, top = 30) +
    labs(y = '% Contribución', title = 'Contribución de variables a Com- 1-2')
)

do.call('grid.arrange', list_contrib_pca)
@
\caption{Contribución de cada variable para PC1, PC2 y el total de la contribución en ambos componentes}
\end{figure}

La línea roja indica el promedio esperado de contribución si las variables fueran uniformes, es decir $ \frac{1}{N° de Variables} = \frac{1}{45} = 2,2\%$. Una variable sobre este umbral se considera importante en la contribución al componente. Se aprecia cómo las interacciones que predominan en ambos componentes están relacionadas con el indicador MACD.

La calidad de representación en el gráfico viene dada por el valor de $Cos^2$, el cual se refiere a la importancia que tiene la variable para interpretar el componente. Para una variable la suma de $Cos^2$ en todas las componentes equivale a 1. En la figura 4.9 se muestra los valores de $Cos^2$ para las primeras 2 componentes

\begin{figure}[H]
\setkeys{Gin}{width = 0.8\textwidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
  fviz_cos2(pca, choice = "var", axes = 1:2, top = 20) +
            labs(y = 'Calidad de la representación', title = 'Calidad de Representación para Com- 1-2')
@
\caption{Calidad de representación medida por $Cos^2$ de cada variable en PC1 y PC2}
\end{figure}

El gráfico de correlación ó Factor map muestra la relación entre las variables. Las claves para su interpretación son:

\begin{itemize}
\item Las variables positivamente correlacionadas se encuentran agrupadas entre sí
\item Las variables negativamente correlacionadas se posicionan en cuadrantes opuestos.
\item La distancia entre las variables y el origen mide la calidad de representación de las variables en el gráfico. Mientras más alejado del origen, mejor representadas 
\end{itemize}

\begin{figure}[H]
\setkeys{Gin}{width = 0.8\textwidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
fviz_pca_var(pca, 
             col.var = "contrib",
             select.var = list(contrib = 45),
             # alpha.var = "contrib",
             repel = TRUE
)
@
\caption{Gráfico de Correlación entre PC1 y PC2}
\end{figure}

En la figura 4.10 se observa el gráfico de correlación para PC1 y PC2, el color de cada variable viene dado por su contribución, mientras más oscuro menor es su contribución a los componentes. Se puede apreciar que las variables con mayor contribución están agrupadas por dos tipos de indicadores predominantes, en el cuadrante superior izquierdo aparecen variables constituidas por interacciones con los indicadores del MACD, mientras que en el cuadrante inferior izquierdo los indicadores predominantes son los rezagos. Se podría resumir que un cuadrante representa la información actual del activo mientras que el otro, la relación entre el precio actual y el precio en períodos anteriores. Por otro lado los grupos forman un ángulo de 90° por lo que no están correlacionados. En los cuadrantes positivos para el eje x predominan variables con una menor contribución a los componentes.

<<Dispersion_Plots, echo=FALSE>>=
aux_scatterplot <- list_serie[[1]] %>% predict_tp(tp = .tp, sl = .sl, h = .h) %>%
  mutate(class_2 = factor(class)) %>% 
  select(-one_of('class')) %>% 
  filter(year(timestamp) %in% seq(2009, 2012, 1))
@

\begin{figure}[H]
\setkeys{Gin}{width = 0.8\textwidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=

fviz_pca_ind(pca, 
             axes = c(1, 2),
             geom.ind = "point",
             select.ind = list(contrib = 900),
             col.ind = aux_scatterplot$class_2)
@
\caption{Gráfico Dispersión entre los componentes. Los puntos rojos representan las observaciones marcadas como 'buys', los triángulos azules los 'stays'}
\end{figure}

En la figura 4.11 se muestra el gráfico de dispersión por clases. Se observa que no hay una región que agrupe una sola clase sino que las observaciones están dispersas en todos los cuadrantes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage

\section{Coeficientes del modelo}

En el presente capítulo se realiza la descripción de los resultados obtenidos después de la aplicación del método propuesto para la estrategia. De igual modo, se presentan los resultados arrojados por las pruebas de Backtesting simulando las entradas y salidas. Los nombres de los componentes fueron sustituidos por etiquetas que intentan explicar la representación del componente en el modelo con ayuda de las gráficas mostradas en la sección 4.1.3

<<Create_Model, echo=FALSE>>=
posit_size <- 10000
list_cm <- list()
list_fr <- list()
list_model <- list()
for(i in 1:length(serie)){
  
  stock <- list_serie[[i]]
  
  # cm <- WFRegression(stock, .tp, .sl, .h, cut = .cut, uniqueBUYs = FALSE)
  cm <- WFRegression(stock, .tp, .sl, .h, cut = .cut, uniqueBUYs = FALSE)
  
  list_cm %<>% rlist::list.append(cm[[1]])
  
  list_model %<>% rlist::list.append(cm[[3]])
  
  prediction <- map_dfr(cm[[2]], as.data.frame) %>% setNames('predict')
  
  data <- stock %>% 
    predict_tp(.tp, .sl, .h) %>% 
    filter(year(timestamp) %in% seq(2013, 2019, 1)) %>% 
    na.omit()
  
  data %<>% cbind(prediction)
  
  long_all <- data %>% longStrat(tp = .tp, sl = .sl, horizon = .h, cap_inic = 100000, ps = posit_size) 
  long_result <- summStrat(long_all)
  
  list_fr %<>% rlist::list.append(long_result)
}
@

En la tabla 4.1 se describen los resultados de los parámetros arrojados por la regresión logística en los 6 períodos de entrenamiento para la serie del S\&P500. Se muestra para cada variable su respectivo coeficiente, así como su error estándar. Se realiza también el contraste Wald - Chi-Cuadrado para verificar la significancia de cada variable en el modelo. Por lo que para cada variable se expone estadístico z que viene dado por $\beta_{i}/SE(\beta_{i})$ y su respectivo p-valor.

El test Wald - Chi-Cuadrado se puede definir de la siguiente manera:

\begin{itemize}
\item \textbf{H0}: $\beta_{i} = 0$
\item \textbf{Hi}: $\beta_{i} \neq 0$
\end{itemize}

\begin{center}
\captionof{table}{Resumen del modelo para cada período de entrenamiento utilizando S\&P500}
\captionof*{table}{Período de entrenamiento 2009 - 2012}
<<echo=FALSE, results=tex>>=
summ_11 <- summary(list_model[[1]][[1]])
row.names(summ_11$coefficients) <- c('(Intercept)',
                                     'ATR.Pos-Macd.Neg',
                                     'Macd.Pos-Rezago.Neg')

xtable(summ_11$coefficients)
@
\end{center}

\begin{center}
\captionof*{table}{Período de entrenamiento 2009 - 2013}
<<echo=FALSE, results=tex>>=
summ_12 <- summary(list_model[[1]][[2]])
row.names(summ_12$coefficients) <- c('(Intercept)',
                                     'ATR.Pos-Macd.Neg',
                                     'Macd.Pos-Rezago.Neg')
xtable(summ_12$coefficients)
@
\end{center}

\begin{center}
\captionof*{table}{Período de entrenamiento 2009 - 2014}
<<echo=FALSE, results=tex>>=
summ_13 <- summary(list_model[[1]][[3]])
row.names(summ_13$coefficients) <- c('(Intercept)',
                                     'ATR.Pos-Macd.Neg',
                                     'Macd.Pos-Rezago.Neg')
xtable(summ_13$coefficients)
@
\end{center}

\newpage
\begin{center}
\captionof*{table}{Período de entrenamiento 2009 - 2015}
<<echo=FALSE, results=tex>>=
summ_14 <- summary(list_model[[1]][[4]])
row.names(summ_14$coefficients) <- c('(Intercept)',
                                     'ATR.Pos-Macd.Neg',
                                     'Macd.Pos-Rezago.Neg')
xtable(summ_14$coefficients)
@
\end{center}

\begin{center}
\captionof*{table}{Período de entrenamiento 2009 - 2016}
<<echo=FALSE, results=tex>>=
summ_15 <- summary(list_model[[1]][[5]])
row.names(summ_15$coefficients) <- c('(Intercept)',
                                     'ATR.Pos-Macd.Neg',
                                     'Macd.Pos-Rezago.Neg')
xtable(summ_15$coefficients)
@
\end{center}


\begin{center}
\captionof*{table}{Período de entrenamiento 2009 - 2017}
<<echo=FALSE, results=tex>>=
summ_16 <- summary(list_model[[1]][[6]])
row.names(summ_16$coefficients) <- c('(Intercept)',
                                     'ATR.Pos-Macd.Neg',
                                     'Precio.Pos-Rezago.Neg')
xtable(summ_16$coefficients)
@
\end{center}

Se observa que recién para el 3er período de entrenamiento se obtiene un p-valor menor a 0.05 lo cual indica que el coeficiente es significativo. A medida que la data de entrenamiento es más grande, los coeficientes son más significativos. Se infiere entonces que mientras más observaciones para entrenar el modelo, mayor será la asociación entre los componentes y la capacidad de predecir el retorno objetivo.

También se observa que el signo de los coeficientes varía en las distintas datas de entrenamiento, por ejemplo para el período 2009-2014 ambas variables influyen positivamente en la correcta predicción del retorno objetivo. En los períodos 2009-2015 y 2009-2016 la variable ATR.Pos-Macd.Neg influye negativamente en la variable dependiente caso contrario para la variable Macd.Pos-Rezago.Neg, que influye positivamente.

\section{Resultados de la simulación}

<<simulation_result, echo=FALSE>>=

df_fr <- data.frame(nrow = 6)
for(i in 1:length(serie)){
  
  aux_buys <- list_fr[[i]][[2]] %>% 
    mutate(predictor = case_when(salida == 'Strategy' & buy_class == 'buy' ~ 'True Buy',
                                 TRUE ~ 'False Buy')) %>% 
    select('predictor') %>% 
    group_by(predictor) %>% 
    summarise(n = n()) %>% 
    setNames(c('metric', i)) %>%
    column_to_rownames(var = 'metric')
  
  aux_metric <- list_fr[[i]][[1]] %>%
    select(c('total_nro_trades', 'perc_predict', 'total_net_profit', 'max_drawdown')) %>% 
    mutate(perc_predict = perc_predict*100, 
           # return_accum = return_accum*100,
           max_drawdown = max_drawdown*100) %>% 
    t() %>% 
    as.data.frame() %>% 
    setNames(i)
    
  aux_fr <- rbind(aux_buys, aux_metric)
  
  df_fr %<>% cbind(aux_fr)
  
}
df_fr[,1] <- NULL

df_fr_show <- df_fr %>% setNames(serie) %>% 
  sapply(sprintf, fmt = c("%.0f", "%.0f", "%.0f", "%1.2f%%", "%.2f", "%1.2f%%")) 

 rownames(df_fr_show) <- c('False Buys', 'True Buys', 'N° trades', 'Accuracy', 
                      'Net Profit', 'Max Drawdown')
@

\begin{center}
\captionof{table}{Resumen de resultados de aplicar el modelo en la data de prueba para los 5 índices}
<<echo=FALSE, results=tex>>=
xtable(df_fr_show, align = rep('c',6))
@
\end{center}

En la tabla 4.2 se muestran los resultados de la simulación para cada uno de los índices. El número de trades cerrados es mayor en los índices BOVESPA y NIKKEI, lo que puede deberse a que estos mercados tuvieron una mayor volatilidad en el período de estudio. Por otra parte la predicción ronda entre 54\% al 62\%, la relación pérdida/ganancia de los parámetros utilizados es $2.5/2 = 1.25$, es decir que por cada trade negativo se necesita 1.25 trades positivos para mitigar la pérdida. En este sentido una precisión del 60\% asegura un margen de ganancia, sin embargo, el retorno acumulado obtenido es pobre comparado con inversiones pasivas del mismo índice.
 
<<trades_plot, echo=FALSE>>=
list_trades_plot <- list()
for(i in 1:length(serie)){
  
  index <- case_when(i == 1 ~ 'S&P500',
                     i == 2 ~ 'NASDAQ',
                     i == 3 ~ 'NIKKEI_225',
                     i == 4 ~ 'FTSE_100',
                     i == 5 ~ 'BOVESPA')
  
  df_serie <- list_serie[[i]] %>% filter(year(timestamp) %in% seq(2013, 2019, 1)) %>% 
    mutate(ind = index) 
  
  aux_trades <- list_fr[[i]][[2]] %>% select(c('buy_date', 'salida')) 
  
  aux_join <- left_join(df_serie, aux_trades, by = c('timestamp' = 'buy_date')) %>% 
    select(c('timestamp', 'salida', 'ind'))
  
  list_trades_plot %<>% rlist::list.append(aux_join)
  
}

df_trades_plot <- map_dfr(list_trades_plot, as.data.frame) %>% 
  mutate(timestamp = as.POSIXct(timestamp))
@

En la figura 4.12 se observa los trades realizados por la simulación según el resultado de la operación, los trades verdes son aquellos clasificados como 'True buys' y resultaron en ganancia, los rojos, son clasificados como 'False buys' y resultaron en pérdidas y los azules son clasificados como 'False buys' pero cerraron el trade por límite de tiempo.

\begin{figure}[H]
\setkeys{Gin}{height = .7\linewidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
df_trades_plot %>% ggplot(aes(x = timestamp, y = ind, color = salida)) +
  geom_point(shape = '|', size = 8) +
  theme_minimal() +
  theme(legend.position = "none", axis.text.x = element_text(angle=45)) + 
  labs(x = NULL, y = NULL) +
  scale_color_manual(values=c('blue3', "red2", "green4")) +
  scale_x_datetime(breaks = "6 month",
                   date_labels = "%b-%y")
@
\caption{Clasificación de la simulación}
\end{figure}

Se observa como en la simulación utilizando el índice BOVESPA, los trades positivos aumentan su frecuencia a partir del segundo semestre del 2016, esto puede deberse al hecho de tener mayor número de observaciones para entrenar el modelo. Igualmente se aprecia como para el S\&P500 las operaciones se concentran en los primeros años de prueba, cerrando los demás años prácticamente sin operaciones.

<<return_plot, echo=FALSE>>=
list_return_plot <- list()
for(i in 1:length(serie)){
  
  index <- case_when(i == 1 ~ 'S&P500',
                     i == 2 ~ 'NASDAQ',
                     i == 3 ~ 'NIKKEI_225',
                     i == 4 ~ 'FTSE_100',
                     i == 5 ~ 'BOVESPA')
  
  aux_return_plot <- list_fr[[i]][[2]] %>% select(c('buy_date', 'profits_ind'))
  
  aux_firstreturn <- data.frame(timestamp = c(dmy('01/01/2013'), as_date(aux_return_plot$buy_date)),
                                cap = c(0, cumsum(aux_return_plot$profits_ind)), #cumprod(aux_return_plot$returns+1)),
                                index = index) %>% 
    mutate(timestamp = as.POSIXct(timestamp))
  
  list_return_plot %<>% rlist::list.append(aux_firstreturn)
  
}

df_return_plot <- map_dfr(list_return_plot, as.data.frame)
@

\begin{figure}[H]
\setkeys{Gin}{width = 1\textwidth}
\centering
<<echo=FALSE, results=tex, fig=TRUE>>=
df_return_plot %>%
  ggplot(aes(x = timestamp, color = index)) +
  geom_line(aes(y = cap)) +
  theme_minimal() +
  theme(legend.position = "top", axis.text.x = element_text(angle=45)) +
  labs(x = NULL, y = 'Retorno Acumulado') +
  scale_y_continuous(breaks = scales::pretty_breaks()) +#, labels = scales::percent) +
  scale_x_datetime(date_breaks = "4 month", date_labels = "%b-%y")
@
\caption{Retorno acumulado para cada índice}
\end{figure}

En la figura 4.13 se observa la curva de capital de las operaciones realizadas con cada uno de los índices. EL NASDAQ y S\&P500 son los de mejor desempeño, mostrando ganancias consistentemente durante todo el período de entrenamiento. Por su lado el NIKKEI y FTSE tienen momentos tanto de ganancia como de pérdida, pero manteniendo un rendimiento positivo. Mientras que el BOVESPA pierde consistentemente durante la primera mitad del período y gana en la segunda mitad, pero terminando con un rendimiento positivo.

\subsection{Medidas de Riesgo}

Al asumir que siempre se abre la posición con la misma cantidad de dinero, en este caso 10.000 USD, se sabe que los trades sólo pueden arrojar dos resultados -0.02\% de ganancia en caso que sea positivo ó 0.025\% de pérdida en caso contrario, descartando las liquidaciones por límite de tiempo- En este sentido se aplica el contraste Wald–Wolfowitz comúnmente llamado test de racha, para verificar la aleatoriedad de los resultados de los trades.

La prueba de Wald–Wolfowitz se puede definir de la siguiente manera:

\begin{itemize}
\item \textbf{H0}: La secuencia es producida de manera aleatoria.
\item \textbf{Hi}: La secuencia no es producida de manera aleatoria.
\end{itemize}

<<runTest, echo=FALSE>>=
c <- .tp*posit_size
d <- .sl*posit_size

list_runtest <- list_fr %>% map(function(x){
  
  x[[2]] %>% 
    select(c('sell_date', 'profits_ind')) %>% 
    filter(profits_ind %in% c(c, -d)) %>% 
    pull(profits_ind) %>%  
    factor() %>% 
    tseries::runs.test()
})
  table_runstest <- list_runtest %>% map_dfr(function(x)x[c('statistic', 'p.value')])
  row.names(table_runstest) <- serie
@
 
\begin{center}
\captionof{table}{Resultados del test de Wald–Wolfowitz (Test de Racha)}
<<echo=FALSE, results=tex>>=
xtable(table_runstest)
@
\end{center}

Frente a p-valores mayores a 0.05, y con un nivel de significación del 5\% no existen elementos suficientes para rechazar la hipótesis nula de aleatoriedad en la secuencia de los resultados de los trades, por lo que se puede concluir que los trades son independientes. Esta independencia permite asumir que la suma de las variables al tener una muestra suficientemente grande, se distribuye N(0, 1). Se calcula entonces el VaR y ES para cada una de las estrategias.

<<Risk_Measure, echo=FALSE>>=

perc_predict <- df_fr["perc_predict",]/100

n <- sqrt(300)
vares <- list()
for(p in perc_predict){
  
  E <- p*c-(1-p)*d
  # v <- (E^2) - ((p*(c^2))-(1-p)*(d^2))
  v <- ((p*(c^2))+(1-p)*(d^2)) - (E^2)
  sd <- sqrt(v)
  
  var <- qnorm(0.95)*(n*sd) - n*E
  es <- (n*sd*dnorm(qnorm(0.95))/0.05) - n*E
  
  vares %<>% rlist::list.append(list(VaR = var, ES = es)) 

}

VaR_df <- vares %>% map_dfr(data.frame) %>% t()
colnames(VaR_df) <- serie

VaR_df %<>% apply(2, function(x) format(round(x, 2), big.mark = ',', nsmal = 2))

@

\begin{center}
\captionof{table}{VaR y ES para retornos de cada índice}
<<echo=FALSE, results=tex>>=
xtable(VaR_df)
@
\end{center}
  
Se puede observar en la tabla 4.4 como el VaR para cada estrategia varía en función de la precisión del modelo, como es de esperar. Para los índices con mayor precisión el VaR es menor y por lo tanto también lo es el ES. En este sentido se puede interpretar el VaR y ES del S\&P500 como: 'Cuando la estrategia toma como activo el índice S\&P500, existe una probabilidad del 5\% de que genere una pérdida igual ó mayor a 6,297.49 USD luego de 300 trades realizados. En caso de que ocurra una pérdida mayor, se espera que el déficit total sea de 7,912.80 USD'